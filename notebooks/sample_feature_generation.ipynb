{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Image feature generation\n",
    "---\n",
    "\n",
    "This notebook is based on the code from \"https://github.com/GVS-Lab/germinal_center/\" by Daniel Paysan and Saradha Venkatachalapathy (2023) and serves as an illustrating example of how to automatically segment biopsy images and extract a number of hand-crafted features curated in the github repository \"https://github.com/GVS-Lab/chrometrics\" from those images.\n",
    "\n",
    "Briefly, this notebook provides functionality to\n",
    "1. Split multi-channel into single-channel images\n",
    "2. Perform image-level intensity normalization\n",
    "3. Segment nuclei using a pretrained StarDist2D model\n",
    "4. Identify approximate cellular masks via nuclear boundary expansion\n",
    "5. Measure cellular protein intensities\n",
    "6. Measure the spatial location of each nucleus in the image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment \n",
    "\n",
    "The first step is always to read in all required external libraries. If any of the external libraries is not yet installed in the environment used to execute the code, it needs to be installed using either conda or pip. Please refer to the respective documentations of Anaconda or pip for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"# import libraries\\nimport sys\\n\\nsys.path.append(\\\"../..\\\")\\n\\nfrom pathlib import Path\\nfrom glob import glob\\nimport pandas as pd\\nimport os\\nfrom tqdm.notebook import tqdm\\n\\nfrom src.batch.nuclear_segmentation import segment_objects_stardist2d\\nfrom src.batch.extract_features import (\\n    extract_nmco_feats_batch,\\n    measure_intensity_batch,\\n    extract_spatial_coordinates_batch,\\n)\\nfrom src.batch.cell_segmentation import cell_seg_dilation_batch\\nfrom src.utils.preprocess_images import (\\n    extract_channel_save_image,\\n    quantile_normalize_and_save_images,\\n)\\nfrom src.utils.cell_type_detection import assign_cell_status\\nfrom src.utils.data_viz import visualize_segmentation_results\\n\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# import libraries\\nimport sys\\n\\nsys.path.append(\\\"../..\\\")\\n\\nfrom pathlib import Path\\nfrom glob import glob\\nimport pandas as pd\\nimport os\\nfrom tqdm.notebook import tqdm\\n\\nfrom src.batch.nuclear_segmentation import segment_objects_stardist2d\\nfrom src.batch.extract_features import (\\n    extract_nmco_feats_batch,\\n    measure_intensity_batch,\\n    extract_spatial_coordinates_batch,\\n)\\nfrom src.batch.cell_segmentation import cell_seg_dilation_batch\\nfrom src.utils.preprocess_images import (\\n    extract_channel_save_image,\\n    quantile_normalize_and_save_images,\\n)\\nfrom src.utils.cell_type_detection import assign_cell_status\\nfrom src.utils.data_viz import visualize_segmentation_results\\n\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")\n",
    "\n",
    "from src.batch.nuclear_segmentation import segment_objects_stardist2d\n",
    "from src.batch.extract_features import *\n",
    "from src.batch.cell_segmentation import *\n",
    "from src.utils.cell_type_detection import assign_cell_status\n",
    "from src.utils.data_viz import visualize_segmentation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the external libraries, we read in a number of functions that we have defined in the ``src`` directory of this code repository. Please look at the code of these functions for a better explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Obtain single-channel from multi-channel images\n",
    "\n",
    "All functions are built to work on single-channel images. Thus, we first obtain one single-channel image for each channel in the raw multi-channel inputs. This can be done via the function below. Note that you need to call that function for each channel of your multi-channel images. Note that python works on a zero-index level. So ``channel=0`` will focus on the first channel in your multi-channel image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extract_channel_save_image(\"path/to/multichannel/images\", \"path/to/images/of/first/channel\", channel=0)\n",
    "    \n",
    "extract_channel_save_image(\"path/to/multichannel/images\", \"path/to/images/of/second/channel\", channel=1)\n",
    "\n",
    "extract_channel_save_image(\"path/to/multichannel/images\", \"path/to/images/of/third/channel\", channel=2)\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the remainder of the notebook, we will assume that the first channel contained the DNA images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Normalize DNA images\n",
    "\n",
    "Depending on the used setup to acquire the images, one might want to normalize the DNA intensities such that explored intensity ranges and the overall intensity distribution of each image looks similar to those of others. To this end, we recommend quantile-based normalization as it is less prone to outliers.\n",
    "\n",
    "The normalization will simply compute the defined quantiles, e.g. the 1-percentile and 99.8-percentile, of the intensities observed in an image and subtract all intensity by the lower one, while scaling it by the difference of the two quantiles. It then rescales the intensities to a scale of 0-255 (8bit resolution) by clipping all values outside that range.\n",
    "\n",
    "The scaled DNA images will be saved in a new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_image_dir = \"/path/to/images/of/first/channel\n",
    "scaled_dna_image_dir = \"/path/to/normalized/images/of/first/channel\"\n",
    "\n",
    "quantile_normalize_and_save_images(dna_image_dir, scaled_dna_image_dir, mask_dir=None,\n",
    "                                   quantiles=[0.01, 0.998])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Segment nuclei\n",
    "\n",
    "We next segment individual nuclei using a pretrained [StarDist](https://github.com/stardist/stardist) model. Please refer to the official StarDist documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_objects_stardist2d(image_dir = scaled_dna_image_dir+\"/\",\n",
    "                               output_dir_labels = /path/to/segmentation/masks,\n",
    "                               output_dir_ijroi = \"/path/to/roi/masks/for/Fiji,\n",
    "                               use_pretrained = True,\n",
    "                               prob_thresh=0.43)\n",
    "                               normalize_quants=[0, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above function you need to specify the location of the directory that contains the DNA images that are to be segmented as the parameter ``image_dir``. We here assume, one has previously obtained quantile-normalized images as described before. \n",
    "\n",
    "The parameter ``output_dir_label`` is set to the directory, where the segmentation masks i.e. images where each pixel gets a 0 if it was identified as background by the segmentation model or a number i>0, where i is the index of the nuclei.\n",
    "\n",
    "The parameter ``output_dir_ijroi`` defines where some other form of representation of the segmented masks should be stored, which can be read in to Fiji's RoI Manager, which can be helpful for instance to easily visualize the segmentations.\n",
    "\n",
    "The ``use_pretrained`` parameter says the function to use a pretrained model. Note that this parameter should on general not be changed.\n",
    "\n",
    "Simarily, the ``prob_thresh`` parameter can be for most cases left as set above. However, if one is not satisfied with the segmentation quality, one could experiment with different choices (between 0 and 1) for that parameter. For an explanation of what that parameter does please refer to the official StarDist documentation linked before.\n",
    "\n",
    "Finally, sometimes additionally enhancing the contrast of the images before segmentation can be beneficial. This could be done by setting the parameter ``norm_quants``. For values greater 0 respectively lower than 100 the contrast gets enhanced via quantile normalization, which we had described before. As a starting point, we recommend using 0 and 100 or setting the paramter to ``normalize_quants=None``.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualization of the segmentation results\n",
    "\n",
    "To visualize the segmentation results, one can plot the DNA image overlaid with differently colored masks for the nuclei or their corresponding outlines. This can be done as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_segmentation_results(\n",
    "    image_dir=scaled_dna_image_dir,\n",
    "    mask_dir=\"path/to/segmentation/masks,\n",
    "    overlay_output_dir=\"/path/to/images/with/overlaid/mask),\n",
    "    outline_output_dir=\"/path/to/images/with/overlaid/outline\",\n",
    "    alpha=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter ``alpha`` controls the opacity of the overlaid masks but usually does not need to be adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Chrometric feature extraction\n",
    "\n",
    "We now profile the chromatin states of the identified nuclei using our developed chrometric features. This can be run in batch mode for all images as follows. The output is stored in the directory defined as the ``output_dir``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuc_features = extract_nmco_feats_batch(\n",
    "    raw_image_path=scaled_dna_image_dir + \"/\",\n",
    "    labelled_image_path=\"/path/to/segmentation/masks/,\n",
    "    output_dir=/path/to/chrometric/features/,\n",
    "    hc_threshold=1,\n",
    "    glcm_lengths=[1,5,20]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two parameters might have to be adjusted for your specific use case. The ``hc_threshold`` parameter determines the separation of each nuclei into hetero- and euchromatin based on the observed DNA intensity. Namely, heterochromatin is identified as those regions, where the observed intensity is greater than the average DNA intensity in the nucleus + ``hc_threshold`` times the standard deviation of the nuclear DNA intensities.\n",
    "\n",
    "The choice of the hyperparameter is optimally based on respective stained images, where one can for a number of individual nuclei images check which choice of the parameter based highlights e.g. heterochromatin as marked by e.g. HP1a.\n",
    "\n",
    "The ``glcm_lengths`` parameter determines the length scales for the GLCM texture features. Note that the units are given in pixels and the choice should be based on the sizes of nuclei that you are working with. The default values of the two parameters is based on a breast cancer study and worked well for the cell types encountered in respective tissues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell segmentation\n",
    "\n",
    "To obtain cellular masks from the nuclear masks, the function below can be run. The function expands the nuclear boundaries up until a certain threshold is reached or it collides with the (expanded) boundaries of other nuclei. This can be seen as an shape-informed variant of Voronoi clustering. The second parameter is the output directory and the first one the one where the nuclear masks are stored in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_seg_dilation_batch(/path/to/segmentation/masks, /path/to/cell/masks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Measuring cellular protein expression\n",
    "\n",
    "We next quantify the expression of the cellular proteins labeled in the other channels of the multi-channel image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd3_levels = measure_intensity_batch(\n",
    "    labelled_image_path=\"/path/to/cell/masks/\",\n",
    "    protein_image_path=\"/path/to/cd3/channel/images\",\n",
    "    output_dir=\"/path/to/cellular/cd3_levels/dir/\",\n",
    ")\n",
    "\n",
    "lamin_levels = measure_intensity_batch(\n",
    "    labelled_image_path=/path/to/cell/masks/,\n",
    "    protein_image_path=\"/path/to/lamin/channel/images\",\n",
    "    output_dir=\"/path/to/cellular/lamin_levels/dir/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we provide an example on how that looks assuming the one had for instance measured the expression of CD3 and Lamin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Compute spatial coordinates of the cells\n",
    "\n",
    "To enable spatial analyses, we also compute the spatial coordinates of the centroids of all segmented cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_coordiates = extract_spatial_coordinates_batch(labelled_image_path = /path/to/segmentation/masks, \n",
    "                        output_dir = /path/to/spatial_coordinates/dir/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, we consolidate all information for all images and save it as a joint file. Note that this is only required if one wants to analyze the data from all images jointly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique nuclei IDs\n",
    "nuc_features['nuc_id'] = nuc_features['image'].astype(str) + '_'+ nuc_features['label'].astype(str)\n",
    "lamin_levels['nuc_id'] = lamin_levels['image'].astype(str) + '_'+ lamin_levels['label'].astype(str)\n",
    "cd3_levels['nuc_id'] = cd3_levels['image'].astype(str) + '_'+ cd3_levels['label'].astype(str)\n",
    "\n",
    "# Save the data aquired\n",
    "consolidated_features_dir = \"/path/to/consolidated/features/dir\"\n",
    "Path(consolidated_features_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "nuc_features.to_csv(consolidated_features_dir+\"/\" +\"nuc_features.csv\")\n",
    "lamin_levels.to_csv(consolidated_features_dir+\"/\" +\"lamin_levels.csv\")\n",
    "cd3_levels.to_csv(consolidated_features_dir+\"/\" +\"cd3_levels.csv\")\n",
    "spatial_coordiates.to_csv(consolidated_features_dir+\"/\" +\"spatial_coordiates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
